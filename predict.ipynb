{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CUDA is available!  Training on GPU ...\ntensor([[-0.4104,  0.5201]], device='cuda:0', grad_fn=<AddmmBackward>)\nEuclidean distance :tensor([[0.6057]], device='cuda:0')\ntensor([0.5201], device='cuda:0', grad_fn=<MaxBackward0>)\ntensor([1], device='cuda:0')\n"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "class FamilyDataset(Dataset):\n",
    "    \"\"\"Family Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.relations = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.relations)\n",
    "    \n",
    "    def __getpair__(self,idx):\n",
    "        pair = self.root_dir+self.relations.iloc[idx,0] + '/' + self.relations.iloc[idx,1],\\\n",
    "        self.root_dir+self.relations.iloc[idx,2] + '/' + self.relations.iloc[idx,3]\n",
    "#         print(pair)\n",
    "        return pair\n",
    "    \n",
    "    def __getlabel__(self,idx):\n",
    "        return self.relations.iloc[idx,4]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pair =  self.__getpair__(idx)\n",
    "        label = self.__getlabel__(idx)\n",
    "        \n",
    "        first = random.choice(os.listdir(pair[0]))\n",
    "        second = random.choice(os.listdir(pair[1]))\n",
    "        \n",
    "        img0 = Image.open(pair[0] + '/' + first)\n",
    "        img1 = Image.open(pair[1] + '/'  + second)\n",
    "#         img0 = img0.convert(\"L\")\n",
    "#         img1 = img1.convert(\"L\")\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "            \n",
    "        return idx,img0,img1,label\n",
    "\n",
    "df=pd.read_csv('./recognizing-faces-in-the-wild/predict.csv')\n",
    "\n",
    "new = df[\"p1\"].str.split(\"/\", n = 1, expand = True)\n",
    "\n",
    "# making separate first name column from new data frame \n",
    "df[\"Family1\"]= new[0]\n",
    "# making separate last name column from new data frame \n",
    "df[\"Person1\"]= new[1]\n",
    "\n",
    "# Dropping old Name columns\n",
    "df.drop(columns =[\"p1\"], inplace = True)\n",
    "\n",
    "new = df[\"p2\"].str.split(\"/\", n = 1, expand = True)\n",
    "\n",
    "# making separate first name column from new data frame \n",
    "df[\"Family2\"]= new[0]\n",
    "# making separate last name column from new data frame \n",
    "df[\"Person2\"]= new[1]\n",
    "\n",
    "# Dropping old Name columns\n",
    "df.drop(columns =[\"p2\"], inplace = True)\n",
    "\n",
    "df['Related']=1\n",
    "df.head()\n",
    "\n",
    "pred_transform = transforms.Compose([transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])])\n",
    "pred_dataset= FamilyDataset(df=df,root_dir=\"./recognizing-faces-in-the-wild/predict/\",transform=pred_transform)\n",
    "\n",
    "pred_dataloader = DataLoader(pred_dataset,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0,\n",
    "                        batch_size=1)\n",
    "dataiter = iter(pred_dataloader)\n",
    "\n",
    "class Vgg_face_dag(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Vgg_face_dag, self).__init__()\n",
    "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
    "                     'std': [1, 1, 1],\n",
    "                     'imageSize': [224, 224, 3]}\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc8 = nn.Linear(in_features=4096, out_features=2622, bias=True)\n",
    "\n",
    "    def forward_once(self, x0):\n",
    "        x1 = self.conv1_1(x0)\n",
    "        x2 = self.relu1_1(x1)\n",
    "        x3 = self.conv1_2(x2)\n",
    "        x4 = self.relu1_2(x3)\n",
    "        x5 = self.pool1(x4)\n",
    "        x6 = self.conv2_1(x5)\n",
    "        x7 = self.relu2_1(x6)\n",
    "        x8 = self.conv2_2(x7)\n",
    "        x9 = self.relu2_2(x8)\n",
    "        x10 = self.pool2(x9)\n",
    "        x11 = self.conv3_1(x10)\n",
    "        x12 = self.relu3_1(x11)\n",
    "        x13 = self.conv3_2(x12)\n",
    "        x14 = self.relu3_2(x13)\n",
    "        x15 = self.conv3_3(x14)\n",
    "        x16 = self.relu3_3(x15)\n",
    "        x17 = self.pool3(x16)\n",
    "        x18 = self.conv4_1(x17)\n",
    "        x19 = self.relu4_1(x18)\n",
    "        x20 = self.conv4_2(x19)\n",
    "        x21 = self.relu4_2(x20)\n",
    "        x22 = self.conv4_3(x21)\n",
    "        x23 = self.relu4_3(x22)\n",
    "        x24 = self.pool4(x23)\n",
    "        x25 = self.conv5_1(x24)\n",
    "        x26 = self.relu5_1(x25)\n",
    "        x27 = self.conv5_2(x26)\n",
    "        x28 = self.relu5_2(x27)\n",
    "        x29 = self.conv5_3(x28)\n",
    "        x30 = self.relu5_3(x29)\n",
    "        x31_preflatten = self.pool5(x30)\n",
    "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
    "        x32 = self.fc6(x31)\n",
    "        x33 = self.relu6(x32)\n",
    "        x34 = self.dropout6(x33)\n",
    "        x35 = self.fc7(x34)\n",
    "        x36 = self.relu7(x35)\n",
    "        x37 = self.dropout7(x36)\n",
    "        x38 = self.fc8(x37)\n",
    "        return x38\n",
    "    \n",
    "    def forward(self,input1,input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        \n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        difference = output1 - output2\n",
    "        return difference,euclidean_distance\n",
    "def vgg_face_dag(weights_path=None, **kwargs):\n",
    "    \"\"\"\n",
    "    load imported model instance\n",
    "\n",
    "    Args:\n",
    "        weights_path (str): If set, loads model weights from the given path\n",
    "    \"\"\"\n",
    "    model = Vgg_face_dag()\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "vggnet = vgg_face_dag(weights_path=\"./pytorch-pretrained-models-for-face-detection/VGG Face\")\n",
    "vggnet = vggnet.cuda()\n",
    "vggnet.eval()\n",
    "for param in vggnet.parameters(): \n",
    "    param.requires_grad = False\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(2622, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(128, 2))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Model().cuda()\n",
    "net.load_state_dict(torch.load('./model.pt'))\n",
    "net.eval()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.008, momentum=0.9)\n",
    "\n",
    "pred_loader = torch.utils.data.DataLoader(pred_dataset,shuffle=True,num_workers=0, batch_size = 1)\n",
    "\n",
    "for i, data in enumerate(pred_loader,0):\n",
    "        row, img0, img1, label = data\n",
    "        row, img0, img1  = row.cuda(), img0.cuda(), img1.cuda() \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output1,euc= vggnet(img0,img1)\n",
    "        output = net(output1)\n",
    "        print(output)\n",
    "        print('Euclidean distance :', euc)\n",
    "        _, pred= torch.max(output,1)\n",
    "print(_)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n"
    }
   ],
   "source": [
    "class Vgg_face_dag(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Vgg_face_dag, self).__init__()\n",
    "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
    "                     'std': [1, 1, 1],\n",
    "                     'imageSize': [224, 224, 3]}\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc8 = nn.Linear(in_features=4096, out_features=2622, bias=True)\n",
    "\n",
    "    def forward_once(self, x0):\n",
    "        x1 = self.conv1_1(x0)\n",
    "        x2 = self.relu1_1(x1)\n",
    "        x3 = self.conv1_2(x2)\n",
    "        x4 = self.relu1_2(x3)\n",
    "        x5 = self.pool1(x4)\n",
    "        x6 = self.conv2_1(x5)\n",
    "        x7 = self.relu2_1(x6)\n",
    "        x8 = self.conv2_2(x7)\n",
    "        x9 = self.relu2_2(x8)\n",
    "        x10 = self.pool2(x9)\n",
    "        x11 = self.conv3_1(x10)\n",
    "        x12 = self.relu3_1(x11)\n",
    "        x13 = self.conv3_2(x12)\n",
    "        x14 = self.relu3_2(x13)\n",
    "        x15 = self.conv3_3(x14)\n",
    "        x16 = self.relu3_3(x15)\n",
    "        x17 = self.pool3(x16)\n",
    "        x18 = self.conv4_1(x17)\n",
    "        x19 = self.relu4_1(x18)\n",
    "        x20 = self.conv4_2(x19)\n",
    "        x21 = self.relu4_2(x20)\n",
    "        x22 = self.conv4_3(x21)\n",
    "        x23 = self.relu4_3(x22)\n",
    "        x24 = self.pool4(x23)\n",
    "        x25 = self.conv5_1(x24)\n",
    "        x26 = self.relu5_1(x25)\n",
    "        x27 = self.conv5_2(x26)\n",
    "        x28 = self.relu5_2(x27)\n",
    "        x29 = self.conv5_3(x28)\n",
    "        x30 = self.relu5_3(x29)\n",
    "        x31_preflatten = self.pool5(x30)\n",
    "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
    "        x32 = self.fc6(x31)\n",
    "        x33 = self.relu6(x32)\n",
    "        x34 = self.dropout6(x33)\n",
    "        x35 = self.fc7(x34)\n",
    "        x36 = self.relu7(x35)\n",
    "        x37 = self.dropout7(x36)\n",
    "        x38 = self.fc8(x37)\n",
    "        return x38\n",
    "    \n",
    "    def forward(self,input1,input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        \n",
    "        #euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        difference = output1 - output2\n",
    "        return difference\n",
    "\n",
    "def vgg_face_dag(weights_path=None, **kwargs):\n",
    "    \"\"\"\n",
    "    load imported model instance\n",
    "\n",
    "    Args:\n",
    "        weights_path (str): If set, loads model weights from the given path\n",
    "    \"\"\"\n",
    "    model = Vgg_face_dag()\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "vggnet = vgg_face_dag(weights_path=\"./pytorch-pretrained-models-for-face-detection/VGG Face\")\n",
    "vggnet = vggnet.cuda()\n",
    "for param in vggnet.parameters(): \n",
    "    param.requires_grad = False\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(2622, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(128, 2))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Model().cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.008, momentum=0.9)\n",
    "\n",
    "pred_loader = torch.utils.data.DataLoader(pred_dataset,shuffle=True,num_workers=0, batch_size = 1)\n",
    "print(len(pred_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1], device='cuda:0')\n"
    }
   ],
   "source": [
    "for i, data in enumerate(pred_loader,0):\n",
    "        row, img0, img1, label = data\n",
    "        row, img0, img1  = row.cuda(), img0.cuda(), img1.cuda() \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output1= vggnet(img0,img1)\n",
    "        output = net(output1)\n",
    "        _, pred= torch.max(output,1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_transform = transforms.Compose([transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])])\n",
    "pred_dataset= FamilyDataset(df=df,root_dir=\"./recognizing-faces-in-the-wild/predict/\",transform=pred_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataloader = DataLoader(pred_dataset,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0,\n",
    "                        batch_size=1)\n",
    "dataiter = iter(pred_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg_face_dag(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Vgg_face_dag, self).__init__()\n",
    "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
    "                     'std': [1, 1, 1],\n",
    "                     'imageSize': [224, 224, 3]}\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc8 = nn.Linear(in_features=4096, out_features=2622, bias=True)\n",
    "\n",
    "    def forward_once(self, x0):\n",
    "        x1 = self.conv1_1(x0)\n",
    "        x2 = self.relu1_1(x1)\n",
    "        x3 = self.conv1_2(x2)\n",
    "        x4 = self.relu1_2(x3)\n",
    "        x5 = self.pool1(x4)\n",
    "        x6 = self.conv2_1(x5)\n",
    "        x7 = self.relu2_1(x6)\n",
    "        x8 = self.conv2_2(x7)\n",
    "        x9 = self.relu2_2(x8)\n",
    "        x10 = self.pool2(x9)\n",
    "        x11 = self.conv3_1(x10)\n",
    "        x12 = self.relu3_1(x11)\n",
    "        x13 = self.conv3_2(x12)\n",
    "        x14 = self.relu3_2(x13)\n",
    "        x15 = self.conv3_3(x14)\n",
    "        x16 = self.relu3_3(x15)\n",
    "        x17 = self.pool3(x16)\n",
    "        x18 = self.conv4_1(x17)\n",
    "        x19 = self.relu4_1(x18)\n",
    "        x20 = self.conv4_2(x19)\n",
    "        x21 = self.relu4_2(x20)\n",
    "        x22 = self.conv4_3(x21)\n",
    "        x23 = self.relu4_3(x22)\n",
    "        x24 = self.pool4(x23)\n",
    "        x25 = self.conv5_1(x24)\n",
    "        x26 = self.relu5_1(x25)\n",
    "        x27 = self.conv5_2(x26)\n",
    "        x28 = self.relu5_2(x27)\n",
    "        x29 = self.conv5_3(x28)\n",
    "        x30 = self.relu5_3(x29)\n",
    "        x31_preflatten = self.pool5(x30)\n",
    "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
    "        x32 = self.fc6(x31)\n",
    "        x33 = self.relu6(x32)\n",
    "        x34 = self.dropout6(x33)\n",
    "        x35 = self.fc7(x34)\n",
    "        x36 = self.relu7(x35)\n",
    "        x37 = self.dropout7(x36)\n",
    "        x38 = self.fc8(x37)\n",
    "        return x38\n",
    "    \n",
    "    def forward(self,input1,input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        \n",
    "        #euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        difference = output1 - output2\n",
    "        return difference\n",
    "\n",
    "def vgg_face_dag(weights_path=None, **kwargs):\n",
    "    \"\"\"\n",
    "    load imported model instance\n",
    "\n",
    "    Args:\n",
    "        weights_path (str): If set, loads model weights from the given path\n",
    "    \"\"\"\n",
    "    model = Vgg_face_dag()\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggnet = vgg_face_dag(weights_path=\"./pytorch-pretrained-models-for-face-detection/VGG Face\")\n",
    "vggnet = vggnet.cuda()\n",
    "for param in vggnet.parameters(): \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(2622, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(128, 2))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.008, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n"
    }
   ],
   "source": [
    "pred_loader = torch.utils.data.DataLoader(pred_dataset,shuffle=True,num_workers=0, batch_size = 1)\n",
    "print(len(pred_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1], device='cuda:0')\n"
    }
   ],
   "source": [
    "for i, data in enumerate(pred_loader,0):\n",
    "        row, img0, img1, label = data\n",
    "        row, img0, img1  = row.cuda(), img0.cuda(), img1.cuda() \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output1= vggnet(img0,img1)\n",
    "        output = net(output1)\n",
    "        _, pred= torch.max(output,1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "26f5c93b-7e6c-4357-91ce-5ca94280dd28",
   "display_name": "'Python Interactive'"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}